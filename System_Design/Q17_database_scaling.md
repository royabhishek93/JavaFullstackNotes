# ğŸ¯ Q17: How to Scale Database for 100k Concurrent Users?

> **Interview Frequency:** 80% | **Difficulty:** â­â­â­â­â­ | **Study Time:** 5 minutes

---

## ğŸ¤” Problem

A successful product has 100k concurrent users. Your database is bottleneck. How do you scale?

---

## ğŸ“Œ Key Strategies

### 1. **Read Replicas** (Most Common)
- Master handles writes
- Replicas handle reads
- Async replication lag acceptable
- Cost: â†‘ Infrastructure

### 2. **Database Sharding**
- Split data by key (user_id % shard_count)
- Each shard is separate database
- Parallel queries on multiple shards
- Complexity: â†‘â†‘â†‘

### 3. **Caching** (Most Effective)
- Redis/Memcached for hot data
- Cache hit rate 80%+ reduces DB load 80%
- Invalidation strategy critical
- Cost: Medium

### 4. **Connection Pooling**
- Reuse connections (HikariCP)
- Don't create new connection per request
- Max 20-50 active connections
- Cheap, high-impact improvement

### 5. **Query Optimization**
- Indexes (B-tree, hash)
- Query plan analysis
- Avoid N+1 problems
- No full table scans

---

## ğŸ’¬ Interview Tip (Say This Exactly)

"For 100k concurrent users: 1) Add read replicas for read scaling, 2) Implement caching (Redis) for hot data, 3) Use connection pooling, 4) Shard by user_id if single database can't handle. Monitor: query latency, connection count, cache hit rate."

---

## ğŸ“š Architecture Flow

```
[100k Users]
     â†“
[API Layer] - Load balanced
     â†“
[Connection Pool] - HikariCP(20-50 connections)
     â†“
[Cache] - Redis (Read hot data here first)
     â†“
[DB Master] - Writes only
  â†™      â†˜
[Replica1] [Replica2] - Read load distributed
```

---

## â˜‘ï¸ Scaling Checklist

- âœ… Step 1: Add read replicas (scale reads 3-5x)
- âœ… Step 2: Implement caching (scale reads 10-20x)
- âœ… Step 3: Connection pooling (prevent connection leak)
- âœ… Step 4: Shard by user_id (if replicas maxed)
- âœ… Monitor: Query latency, connection active count, cache hit %

---

## âš ï¸ Common Pitfalls

**Pitfall 1: Sharding too early**
```
// âŒ Company with 1000 users implements sharding
// Result: Complexity explosion for no benefit

// âœ… Scaling order:
1. Optimize queries + indexes (free, 10x improvement)
2. Add caching (cheap, 10-20x improvement)
3. Add read replicas (medium cost, 3-5x improvement)
4. Shard database (LAST RESORT - complexity cost is high)
```

**Pitfall 2: Not using connection pooling**
```java
// âŒ Creating new connection per request
public User getUser(int id) {
    Connection conn = DriverManager.getConnection(url);  // 50-100ms overhead!
    // Query takes 5ms, connection creation takes 50ms
}

// âœ… Use connection pool (HikariCP)
@Bean
public DataSource dataSource() {
    HikariConfig config = new HikariConfig();
    config.setMaximumPoolSize(20);  // Reuse connections
    return new HikariDataSource(config);
}
```

**Pitfall 3: Sending writes to read replicas**
```java
// âŒ Write-after-read inconsistency
userService.updateEmail(userId, newEmail);  // Write to master
User user = userService.getUser(userId);  // Read from replica - OLD EMAIL!
// Replication lag (10-100ms) causes stale read

// âœ… Read from master after write
@Transactional
public void updateAndNotify(int userId, String newEmail) {
    userRepo.updateEmail(userId, newEmail);  // Master
    User user = userRepo.findById(userId);  // Force master read
    emailService.send(user.getEmail());  // Sends to correct email
}
```

**Pitfall 4: Not monitoring replication lag**
```
// âŒ Replica is 5 minutes behind, users see old data
// No alerts, no monitoring

// âœ… Monitor replication lag
SELECT TIMESTAMPDIFF(SECOND, executed_gtid_set, received_gtid_set) AS lag;
Alert if lag > 1 second
```

**Pitfall 5: Over-caching without invalidation strategy**
```java
// âŒ Cache never expires, stale data forever
cache.put("user:" + id, user);  // No TTL!

// âœ… Cache with TTL + invalidation
cache.put("user:" + id, user, 5, TimeUnit.MINUTES);  // Auto-expire

@Transactional
public void updateUser(User user) {
    userRepo.save(user);
    cache.evict("user:" + user.getId());  // Explicit invalidation
}
```

---

## ğŸ›‘ When NOT to Use Each Strategy

- âŒ **Read Replicas**: Write-heavy workloads (replicas won't help)
- âŒ **Sharding**: Small datasets (<1M rows), low traffic (<1k concurrent users)
- âŒ **Caching**: Data changes frequently (cache hit rate <50%)
- âŒ **Connection Pooling**: Single-user applications (no concurrency)
- âœ… **DO**: Start simple, measure, then scale based on bottlenecks

---

## ğŸ”— Related Questions

- [Q18_caching_strategies.md](Q18_caching_strategies.md) - Caching layers for read scaling
- [Q19_load_balancing.md](Q19_load_balancing.md) - Load balancer configuration
- [../Core_Java/Database_SQL/Q24_n_plus_one_problem.md](../Core_Java/Database_SQL/Q24_n_plus_one_problem.md) - Query optimization patterns
- [../Core_Java/Database_SQL/Q28_connection_pooling.md](../Core_Java/Database_SQL/Q28_connection_pooling.md) - HikariCP tuning

---

**Last Updated:** February 22, 2026  
**Next: [Q18_caching_strategies.md](Q18_caching_strategies.md)**
